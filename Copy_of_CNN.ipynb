{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CNN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+2YQLM82e5yiO5sjteM/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshadNSuthar/CNN-using-keras-in-tensorflow/blob/master/Copy_of_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBUG1w2Vk4XF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing all required packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il4eCM9w5hye",
        "colab_type": "code",
        "outputId": "a0293a16-dec2-4f12-953b-eb6cac2109f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXy7jEFf63Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = '/content/drive/My Drive/Final_Train'\n",
        "test_set = '/content/drive/My Drive/Final_Test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTB9LQLUFA6Z",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSFj0YolLtZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing the CNN\n",
        "classifier = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNUmpO_uLwBd",
        "colab_type": "code",
        "outputId": "aced24bb-e9a4-4acf-a563-cf2dac819671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Step 1 Convolution\n",
        "#Filter = Feature detecter (32,3,3)  \n",
        "# input = expeted image pixel\n",
        "classifier.add(Convolution2D(32,3,3,input_shape = (64, 64, 3), activation= 'relu' ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fElYagSMX-uV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2 Pooling\n",
        "# pool_size = recommened 2,2\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCJLMMI2Zkpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Step 3 Flatteinig\n",
        "#This step consist taking all Pooled Feature Map into one single vector\n",
        "\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7mSnZSpbIrz",
        "colab_type": "code",
        "outputId": "73396ec7-2547-446f-d691-6574b61966c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Step4 Full connection\n",
        "# output_dim = 120 (choice of result come from experiemt number around 100 is good)\n",
        "# we used Sigmoid activation fuction as we have only 2 outcome\n",
        "\n",
        "classifier.add(Dense(output_dim = 120, activation='relu'))\n",
        "classifier.add(Dense(output_dim = 1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsKJkd4Tc1wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the ANN\n",
        "\n",
        "# here we will use adam(stocastic gradient decent) algorithm\n",
        "# if dependent is binary category then lugaric loss function  is called binary_crosssentropy\n",
        "# if denendent is more then 2 category then lugaric loss function called categorical_crossentropy\n",
        "\n",
        "classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics = ['accuracy'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q20nNAZKdduY",
        "colab_type": "code",
        "outputId": "893d5b10-b22b-4d0b-9227-0455ff67e891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "#Part 2 = Fitting the CNN to the image\n",
        "# Copied this code from keras preprocessing \n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_set = train_datagen.flow_from_directory('/content/drive/My Drive/Final_Train',\n",
        "                                              target_size=(64, 64),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Final_Test',\n",
        "                                                        target_size=(64, 64),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='binary')\n",
        "classifier.fit_generator(train_set,\n",
        "                         steps_per_epoch=2000,\n",
        "                         epochs=25,\n",
        "                         validation_data= test_set,\n",
        "                         validation_steps=500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2020 images belonging to 2 classes.\n",
            "Found 500 images belonging to 2 classes.\n",
            "Epoch 1/25\n",
            "2000/2000 [==============================] - 1064s 532ms/step - loss: 0.4437 - accuracy: 0.7900 - val_loss: 0.7510 - val_accuracy: 0.7234\n",
            "Epoch 2/25\n",
            "2000/2000 [==============================] - 571s 286ms/step - loss: 0.1797 - accuracy: 0.9289 - val_loss: 1.0284 - val_accuracy: 0.7486\n",
            "Epoch 3/25\n",
            "2000/2000 [==============================] - 578s 289ms/step - loss: 0.0708 - accuracy: 0.9756 - val_loss: 0.5245 - val_accuracy: 0.7540\n",
            "Epoch 4/25\n",
            "2000/2000 [==============================] - 569s 284ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 2.6578 - val_accuracy: 0.7202\n",
            "Epoch 5/25\n",
            "2000/2000 [==============================] - 557s 278ms/step - loss: 0.0345 - accuracy: 0.9886 - val_loss: 1.4660 - val_accuracy: 0.7298\n",
            "Epoch 6/25\n",
            "2000/2000 [==============================] - 559s 279ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 3.2304 - val_accuracy: 0.7189\n",
            "Epoch 7/25\n",
            "2000/2000 [==============================] - 568s 284ms/step - loss: 0.0199 - accuracy: 0.9935 - val_loss: 2.8899 - val_accuracy: 0.6817\n",
            "Epoch 8/25\n",
            "2000/2000 [==============================] - 567s 283ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.8640 - val_accuracy: 0.7223\n",
            "Epoch 9/25\n",
            "2000/2000 [==============================] - 581s 290ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 2.4113 - val_accuracy: 0.6702\n",
            "Epoch 10/25\n",
            "2000/2000 [==============================] - 576s 288ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 3.5808 - val_accuracy: 0.7093\n",
            "Epoch 11/25\n",
            "2000/2000 [==============================] - 565s 282ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 2.2993 - val_accuracy: 0.7018\n",
            "Epoch 12/25\n",
            "2000/2000 [==============================] - 555s 277ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 2.6282 - val_accuracy: 0.6857\n",
            "Epoch 13/25\n",
            "2000/2000 [==============================] - 556s 278ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 3.7913 - val_accuracy: 0.6902\n",
            "Epoch 14/25\n",
            "2000/2000 [==============================] - 574s 287ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 2.7395 - val_accuracy: 0.7023\n",
            "Epoch 15/25\n",
            "2000/2000 [==============================] - 575s 287ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 2.1193 - val_accuracy: 0.7013\n",
            "Epoch 16/25\n",
            "2000/2000 [==============================] - 569s 284ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 7.0559 - val_accuracy: 0.6883\n",
            "Epoch 17/25\n",
            "2000/2000 [==============================] - 560s 280ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 1.9523 - val_accuracy: 0.6766\n",
            "Epoch 18/25\n",
            "2000/2000 [==============================] - 556s 278ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 1.9461 - val_accuracy: 0.7235\n",
            "Epoch 19/25\n",
            "2000/2000 [==============================] - 555s 278ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.1876 - val_accuracy: 0.7248\n",
            "Epoch 20/25\n",
            "2000/2000 [==============================] - 577s 289ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 2.0170 - val_accuracy: 0.6802\n",
            "Epoch 21/25\n",
            "2000/2000 [==============================] - 590s 295ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 3.3125 - val_accuracy: 0.7161\n",
            "Epoch 22/25\n",
            "2000/2000 [==============================] - 576s 288ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 2.6197 - val_accuracy: 0.6879\n",
            "Epoch 23/25\n",
            "2000/2000 [==============================] - 563s 281ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 3.0058 - val_accuracy: 0.7048\n",
            "Epoch 24/25\n",
            "2000/2000 [==============================] - 562s 281ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 5.7561 - val_accuracy: 0.6919\n",
            "Epoch 25/25\n",
            "2000/2000 [==============================] - 568s 284ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 2.3566 - val_accuracy: 0.6957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0f69e93e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qBdT7AVslch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We got 0.9971 accuracy on training set and 0.6957 accuracy on test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTEwopsOVRLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can improve the  accuracy of test set by adding more convolution layers \n",
        "# We can improve the accuracy by duing tuning "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU_GJ7AiauTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Due to time limit not added "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}